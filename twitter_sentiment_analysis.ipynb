{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8428e8b5",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Project:</b> TWITTER SENTIMENT ANALYSIS - MODEL FOR PREDICTING POLARITY\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d847204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9600000"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing data into dataframe\n",
    "import pandas as pd\n",
    "data = pd.read_csv(r\"C:\\Users\\USER\\Downloads\\twitter_new.csv\", encoding='latin-1', names=['target','id','date', 'flag', 'user', 'text'])\n",
    "\n",
    "data.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24f7173",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For training purpose we will use only a small portion of the given data ,here 10000 samples 5000+5000.\n",
    "from random import sample\n",
    "pos = data[data['target']==4]\n",
    "neg = data[data['target']==0]\n",
    "samp_pos = pos.sample(5000)\n",
    "samp_neg = neg.sample(5000)\n",
    "\n",
    "samp = pd.concat([samp_pos, samp_neg], axis=0)\n",
    "samp['target'] = samp['target'].replace([4],1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e89338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will use this samp dataset to test our code for text preprocessing.\n",
    "#text pre-processing steps\n",
    "#1. Converting to lower case\n",
    "def lower(tweet):\n",
    "    return (tweet.lower())\n",
    "\n",
    "#2. Remove numbers using regex.\n",
    "import re\n",
    "def rm_digits(tweet):\n",
    "    result = re.sub(r'/d+', '', tweet)\n",
    "    return result\n",
    "#3. Remove punctuations\n",
    "import string\n",
    "def rm_punct(tweet):\n",
    "    for punctuation in string.punctuation:\n",
    "        tweet = tweet.replace(punctuation, '')\n",
    "    return tweet    \n",
    "\n",
    "#4. Remove whitespaces\n",
    "def rm_whitespaces(tweet):\n",
    "    res = \" \".join(tweet.split()) \n",
    "    return res\n",
    "\n",
    "#5. Remove stopwords\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "def rm_stpwrds(tweet):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(tweet)\n",
    "    res = [x for x in word_tokens if x not in stop_words]\n",
    "    return res\n",
    "\n",
    "#6. Stemming - Converting the word tokens to stem/root word(Grouping of different inflected forms of same words)\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "def stemr(tweet):\n",
    "    stemmer = PorterStemmer()\n",
    "    res = [stemmer.stem(x) for x in tweet]\n",
    "    return res\n",
    "    \n",
    "#7. Lemmatization - to get valid words from the word tokens\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "def lem(tweet):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    res = [lemmatizer.lemmatize(x, pos='v') for x in tweet]\n",
    "    return res\n",
    "    \n",
    "def join_tokens(tweet):\n",
    "    res = ' '.join(tweet)\n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "#lower case\n",
    "samp['text'] = samp['text'].apply(lambda x: lower(x))\n",
    "#Digit removal\n",
    "samp['text'] = samp['text'].apply(lambda x: rm_digits(x))\n",
    "#Punctuation removal\n",
    "samp['text'] = samp['text'].apply(lambda x: rm_punct(x))\n",
    "#Whitespace removal\n",
    "samp['text'] = samp['text'].apply(lambda x: rm_whitespaces(x))\n",
    "#removing stopwords\n",
    "samp['text'] = samp['text'].apply(lambda x: rm_stpwrds(x))\n",
    "#stemming\n",
    "samp['text'] = samp['text'].apply(lambda x: stemr(x))\n",
    "#lemmatizing\n",
    "samp['text'] = samp['text'].apply(lambda x: lem(x))\n",
    "\n",
    "\n",
    "\n",
    "# Converting the samp['text'] back to text usig join\n",
    "samp['text'] = samp['text'].apply(lambda x: join_tokens(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f567b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# extract the features using count vectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "vectorizer = CountVectorizer(dtype ='uint8')\n",
    "df_countvectorizer = vectorizer.fit_transform(samp['text'])\n",
    "df_countvectorizer.shape\n",
    "\n",
    "# splitting the features into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(  \n",
    "                                                df_countvectorizer,  \n",
    "                                                samp[\"target\"],   \n",
    "                                                test_size=0.2,  \n",
    "                                                 random_state=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17a8c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of features (unique words)\n",
    "num_features = len(vectorizer.vocabulary_)\n",
    "print(num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf199c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multinomial Naive Bayes Classifier\n",
    "# Logistic Classifier\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "\n",
    "Log_classifier = LogisticRegression(max_iter=1500)\n",
    "Log_classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "MNB_classifier = MultinomialNB()\n",
    "MNB_classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "svc = svm.SVC(kernel = 'linear')\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc10c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting the labels \n",
    "from sklearn import metrics\n",
    "\n",
    "model_list = [Log_classifier, MNB_classifier, svc]\n",
    "\n",
    "for classifier in model_list:\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    acc = metrics.accuracy_score(y_test,y_pred)\n",
    "    precision  = metrics.precision_score(y_test, y_pred)\n",
    "    recall = metrics.recall_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Performace of {classifier}\")\n",
    "    print(f\"Accuracy = {acc}\")\n",
    "    print(f\"Precision = {precision}\")\n",
    "    print(f\"Recall = {recall}\", end = '\\n')\n",
    "    \n",
    "    print(\"--\"*55)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877e2bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model accuracy\n",
    "#print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d7a5b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2144c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fcb1a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9387094e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
